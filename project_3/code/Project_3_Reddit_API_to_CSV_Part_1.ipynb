{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit API to CSV\n",
    "   ---\n",
    "  *By Ethan Koh, 18 May 2020*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap Reddit API and save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CasualConversation' Subreddit to scrap from\n",
    "url = 'https://www.reddit.com/r/CasualConversation.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87a5266180043a4800fa826d1fc3766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?&limit=50\n",
      "Number of posts : 52\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gioe5v&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gioteo&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gil7d6&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gi3enz&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gi2ed7&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_ghpcys&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_ghnmu1&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gh3kkh&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gh5iu0&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gh09tx&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_ggyc8o&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_ggnc2v&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gg6o4w&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/CasualConversation.json?after=t3_gg54an&limit=50\n",
      "Number of posts : 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store\n",
    "posts = []\n",
    "after = None\n",
    "\n",
    "# number of pages retrieved\n",
    "for a in tqdm(range(15)):\n",
    "    \n",
    "    # first page\n",
    "    if after == None:\n",
    "        current_url = url + '?&limit=50'\n",
    "    else:\n",
    "    #subsequent pages\n",
    "        current_url = url + '?after=' + after + '&limit=50'\n",
    "        \n",
    "    # View url scraped\n",
    "    print('Retrieved from : '+ current_url)\n",
    "    \n",
    "    # Request API\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "    # Check for status error\n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    # if no error, continue. \n",
    "    # Get post into dataframe\n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    \n",
    "    # View number of posts retrieved from page\n",
    "    print('Number of posts : '+str(len(current_posts)))\n",
    "    posts.extend(current_posts)\n",
    "    \n",
    "    # store next page directory\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    # if not looking at first page of reddit, store data in prev_posts in case status error\n",
    "    if a > 0:\n",
    "        prev_posts = pd.read_csv('../data/CasualConversation.csv')\n",
    "        current_df = pd.DataFrame()\n",
    "    \n",
    "    # create csv if looking at first page of reddit\n",
    "    else:\n",
    "        pd.DataFrame(posts).to_csv('../data/CasualConversation.csv', index = False)\n",
    "\n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,8)\n",
    "    time.sleep(sleep_duration) # sleep_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of posts retrieved\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv \n",
    "pd.DataFrame(posts).to_csv('../data/CasualConversation.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Parenting' Subreddit to scrap from\n",
    "url_2 = 'https://www.reddit.com/r/Parenting.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8543e37fa02645c3ae7a9347623bdfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved from : https://www.reddit.com/r/Parenting.json?&limit=50\n",
      "Number of posts : 52\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gi5d6w&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_ghlhqh&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gggoxr&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gfv930&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gf63wk&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gfm4mj&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gf7h45&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gettsy&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gejh78&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gdzqr7&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gdbvbj&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gcza2u&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gcjtjp&limit=50\n",
      "Number of posts : 50\n",
      "Retrieved from : https://www.reddit.com/r/Parenting.json?after=t3_gccsnt&limit=50\n",
      "Number of posts : 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to store\n",
    "posts = []\n",
    "after = None\n",
    "\n",
    "# number of pages retrieved\n",
    "for a in tqdm(range(15)):\n",
    "    \n",
    "    # first page\n",
    "    if after == None:\n",
    "        current_url = url_2 + '?&limit=50'\n",
    "    else:\n",
    "    #subsequent pages\n",
    "        current_url = url_2 + '?after=' + after + '&limit=50'\n",
    "        \n",
    "    # View url scraped\n",
    "    print('Retrieved from : '+ current_url)\n",
    "    \n",
    "    # Request API\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "    # Check for status error\n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    # if no error, continue. \n",
    "    # Get post into dataframe\n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    \n",
    "    # View number of posts retrieved from page\n",
    "    print('Number of posts : '+str(len(current_posts)))\n",
    "    posts.extend(current_posts)\n",
    "    \n",
    "    # store next page directory\n",
    "    after = current_dict['data']['after']\n",
    "    \n",
    "    # if not looking at first page of reddit, store data in prev_posts in case status error\n",
    "    if a > 0:\n",
    "        prev_posts = pd.read_csv('../data/CasualConversation.csv')\n",
    "        current_df = pd.DataFrame()\n",
    "    \n",
    "    # create csv if looking at first page of reddit\n",
    "    else:\n",
    "        pd.DataFrame(posts).to_csv('../data/CasualConversation.csv', index = False)\n",
    "\n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,8)\n",
    "    time.sleep(sleep_duration) # sleep_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of posts retrieved\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv \n",
    "pd.DataFrame(posts).to_csv('../data/Parenting.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
